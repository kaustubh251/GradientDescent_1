# GradientDescent_1
Linear regression problem is solved by using gradient descent algorithm.
A straight was fit to the given data.
Observations and Conclusion:
Gradient descent algorithm was dependent on learning rate (alpha).
The cost function was blowing up to 'inf' for very high learning rate.
For smaller alpha we might not get converged value of parameters (theta[0] and theta[1]).
More knowledge and experience is to be needed while choosing learning rate.
Gradient descent is preferable as matrix operations require time of O(N2) whereas gradient descent require time of O(N).
